{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import glob\n",
    "import math\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Reading The Video frame by frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture(r'.\\Project_data\\project_video.mp4')\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "frm_list = []\n",
    "frm_list.append(image)\n",
    "while success:\n",
    "    #cv2.imwrite(r'.\\Project_data\\frames\\frame%d.jpg' % count, image) #saving frames as jpg\n",
    "    frm_list.append(image)\n",
    "    success, image = vidcap.read()\n",
    "    #print(\"Read a new frame: \", success)\n",
    "    #count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, title=\"title\", cmap_type=\"gray\"):\n",
    "    plt.imshow(image, cmap_type)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying gaussian blur\n",
    "def gaussian_blur(image,height,width):\n",
    "    return cv2.GaussianBlur(image,(height, width),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    match_mask_color = 255\n",
    "    \n",
    "    cv2.fillPoly(mask, vertices, match_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_image(combined_binary):\n",
    "    offset = 100\n",
    "    mask_poly =np.array([[(0 + offset, image.shape[0]),\n",
    "                            (image.shape[1] / 2.3, image.shape[0] / 1.65),\n",
    "                            (image.shape[1] / 1.7, image.shape[0] / 1.65),\n",
    "                            (image.shape[1], image.shape[0])]],\n",
    "                          dtype=int)\n",
    "    mask_img = np.zeros_like(combined_binary)\n",
    "    ignore_mask_color = 255\n",
    "    cv2.fillPoly(mask_img, mask_poly, ignore_mask_color)\n",
    "    masked_edges = cv2.bitwise_and(combined_binary, mask_img)\n",
    "    return masked_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Perspective Transform Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp(image, src, dst):\n",
    "\n",
    "    src = np.float32([src])\n",
    "    dst = np.float32([dst])\n",
    "    \n",
    "    return cv2.warpPerspective(image, cv2.getPerspectiveTransform(src, dst),\n",
    "                               dsize=image.shape[0:2][::-1], flags=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_warped_image_histogram(image):\n",
    "    return np.sum(image[image.shape[0] // 2:, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, n_windows=9):\n",
    "    # Get Binary image histogram\n",
    "    histogram = get_warped_image_histogram(image)\n",
    "    \n",
    "    # Allow image to be RGB to display sliding windows.\n",
    "    out = np.dstack((image, image, image)) * 255\n",
    "    \n",
    "    # Get Center of left and right peaks.\n",
    "    midpoint = histogram.shape[0] // 2\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # Calculate window height.\n",
    "    window_height = image.shape[0] // n_windows\n",
    "    \n",
    "    # Get indicies that map to non zero values.\n",
    "    non_zero_y, non_zero_x = map(lambda x: np.array(x), image.nonzero())\n",
    "    \n",
    "    margin = 50 # Width of sliding window.\n",
    "    min_pixels = 50 # Min amount of pixels that match inside the window to detect a lane.\n",
    "    \n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    left_lane_indicies = []\n",
    "    right_lane_indicies = []\n",
    "    \n",
    "    for window in range(n_windows):\n",
    "        # Calculate window vertices positions.\n",
    "        win_y_low = image.shape[0] - (window + 1) * window_height # Y coordinate of top corners. \n",
    "        win_y_high = image.shape[0] - window * window_height # Y coordinate of bottom corners.\n",
    "        win_xleft_low = leftx_current - margin # X coordinate of left side of the window at the left side of the lane.\n",
    "        win_xleft_high = leftx_current + margin # X coordinate of right side of the window at the left side of the lane.\n",
    "        win_xright_low = rightx_current - margin # X coordinate of left side of the window at the right side of the lane.\n",
    "        win_xright_high = rightx_current + margin # X coordinate of right side of the window at the right side of the lane.\n",
    "        \n",
    "        # Draw green rectangle at current windows.\n",
    "        cv2.rectangle(out, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high), (0, 255, 0), 2)\n",
    "        cv2.rectangle(out, (win_xright_low, win_y_low), (win_xright_high, win_y_high), (0, 255, 0), 2)\n",
    "        \n",
    "        good_left_indicies = ((non_zero_y >= win_y_low) & (non_zero_y < win_y_high) & (non_zero_x >= win_xleft_low) & (\n",
    "            non_zero_x < win_xleft_high)).nonzero()[0] # Check if index is inside the left window.\n",
    "        good_right_indicies = ((non_zero_y >= win_y_low) & (non_zero_y < win_y_high) & (non_zero_x >= win_xright_low) & (\n",
    "            non_zero_x < win_xright_high)).nonzero()[0] # Check if index is inside the right window.\n",
    "        \n",
    "        left_lane_indicies.append(good_left_indicies)\n",
    "        right_lane_indicies.append(good_right_indicies)\n",
    "        \n",
    "        # Shift left to the mean.\n",
    "        if len(good_left_indicies) > min_pixels:\n",
    "            leftx_current = int(np.mean(non_zero_x[good_left_indicies]))\n",
    "        if len(good_right_indicies) > min_pixels:\n",
    "            rightx_current = int(np.mean(non_zero_x[good_right_indicies]))\n",
    "    \n",
    "    left_lane_indicies = np.concatenate(left_lane_indicies)\n",
    "    right_lane_indicies = np.concatenate(right_lane_indicies)\n",
    "\n",
    "    # Pixels that matched in the left side of the lane.\n",
    "    left_x = non_zero_x[left_lane_indicies]\n",
    "    left_y = non_zero_y[left_lane_indicies]\n",
    "    \n",
    "    # Pixels that matched in the right side of the lane.\n",
    "    right_x = non_zero_x[right_lane_indicies]\n",
    "    right_y = non_zero_y[right_lane_indicies]\n",
    "\n",
    "    # Fit the points using a second degree polynomial.\n",
    "    left_fit = np.polyfit(left_y, left_x, 2)\n",
    "    right_fit = np.polyfit(right_y, right_x, 2)\n",
    "        \n",
    "    return out, left_fit, right_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines_and_fill(image, warped_image, left_fit, right_fit, src, dest):\n",
    "    \n",
    "    # Make a zero like copy of warped image.\n",
    "    warp_zero = np.zeros_like(warped_image).astype(np.uint8)\n",
    "    \n",
    "    # Make rgb image of zeros.\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Create a y axis.\n",
    "    ploty = np.linspace(0, image.shape[0] - 1, image.shape[0])\n",
    "        \n",
    "    # Left line polynomial.\n",
    "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    # Right Line polynomial.\n",
    "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    #cv2.fillPoly(color_warp_center, np.int_([pts]), (0, 255, 0))\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (255, 255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = warp(color_warp, dest, src)\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(image, 1, newwarp, 0.2, 0)\n",
    "\n",
    "    color_warp_lines = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    cv2.polylines(color_warp_lines, np.int_([pts_left]), isClosed=False, color=(0, 0, 255), thickness=25)\n",
    "    cv2.polylines(color_warp_lines, np.int_([pts_right]), isClosed=False, color=(0, 0, 255), thickness=25)\n",
    "    newwarp_lines = warp(color_warp_lines, dest, src)\n",
    "\n",
    "    result = cv2.addWeighted(result, 1, newwarp_lines, 1, 0)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Calculating Curve Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_meters(Perspective_img, left_fitx, right_fitx, ploty):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Calculating Vehicle Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_position_meters(Perspective_img, left_fit, right_fit):\n",
    "    # Define conversion in x from pixels space to meters\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    # Choose the y value corresponding to the bottom of the image\n",
    "    y_max = Perspective_img.shape[0]\n",
    "    # Calculate left and right line positions at the bottom of the image\n",
    "    left_x_pos = left_fit[0]*y_max**2 + left_fit[1]*y_max + left_fit[2]\n",
    "    right_x_pos = right_fit[0]*y_max**2 + right_fit[1]*y_max + right_fit[2] \n",
    "    # Calculate the x position of the center of the lane \n",
    "    center_lanes_x_pos = (left_x_pos + right_x_pos)//2\n",
    "    # Calculate the deviation between the center of the lane and the center of the picture\n",
    "    # The car is assumed to be placed in the center of the picture\n",
    "    # If the deviation is negative, the car is on the felt hand side of the center of the lane\n",
    "    veh_pos = ((Perspective_img.shape[1]//2) - center_lanes_x_pos) * xm_per_pix \n",
    "    return veh_pos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Processing the Video Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "final_list = []\n",
    "\n",
    "#height = image.shape[0]\n",
    "#print(height)\n",
    "#width = image.shape[1]\n",
    "#print(width)\n",
    "height, width, layers = frm_list[1].shape\n",
    "size = (width,height)\n",
    "\n",
    "region_of_interest_vertices = [\n",
    "    (0, height),\n",
    "    (width / 2,400),\n",
    "    (width, height),\n",
    "]\n",
    "\n",
    "src = [595, 452], \\\n",
    "          [685, 452], \\\n",
    "          [1110, frm_list[1].shape[0]], \\\n",
    "          [220, frm_list[1].shape[0]]\n",
    "line_dst_offset = 100\n",
    "dst = [src[3][0] + line_dst_offset, 0], \\\n",
    "          [src[2][0] - line_dst_offset, 0], \\\n",
    "          [src[2][0] - line_dst_offset, src[2][1]], \\\n",
    "          [src[3][0] + line_dst_offset, src[3][1]]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(frm_list)):\n",
    "    gray = cv2.cvtColor(frm_list[i], cv2.COLOR_BGR2GRAY)\n",
    "    #cannyed_image = cv2.Canny(gray,100,200, L2gradient = True)\n",
    "    blurred = gaussian_blur(gray,7,7)\n",
    "    cropped_image = region_of_interest(\n",
    "        blurred,\n",
    "        np.array([region_of_interest_vertices], np.int32)\n",
    "    )\n",
    "\n",
    "    (T, threshInv) = cv2.threshold(cropped_image, 200, 255,cv2.THRESH_BINARY)\n",
    "    #cv2.imshow(\"Threshold Binary Inverse\", threshInv)\n",
    "    #show_image(threshInv)\n",
    "    masked = cv2.bitwise_and(frm_list[i], frm_list[i], mask=threshInv)\n",
    "    #plt.imshow(masked)\n",
    "    #show_image(masked)\n",
    "\n",
    "    hls = cv2.cvtColor(frm_list[i], cv2.COLOR_RGB2HLS)\n",
    "    gray = hls[:, :, 1]\n",
    "    s_channel = hls[:, :, 2]\n",
    "\n",
    "    sobel_kernel=7\n",
    "    mag_thresh=(3, 255)\n",
    "    s_thresh=(170, 255)\n",
    "    th=(10,100)\n",
    "\n",
    "    sobel_binary = np.zeros(shape=gray.shape, dtype=bool)\n",
    "    s_binary = sobel_binary\n",
    "    combined_binary = s_binary.astype(np.float32)\n",
    "\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=7)\n",
    "    sobely = 0\n",
    "    #sobelxy = cv2.Sobel(gray, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=7)\n",
    "    #show_image(sobelx)\n",
    "    edges = cv2.Canny(gray, threshold1=100, threshold2=200) # Canny Edge Detection\n",
    "    # Display Canny Edge Detection Image\n",
    "    #show_image(edges)\n",
    "\n",
    "    sobel_abs = np.abs(sobelx**2 + sobely**2)\n",
    "    sobel_abs = np.uint8(255 * sobel_abs / np.max(sobel_abs))\n",
    "\n",
    "    sobel_binary[(sobel_abs > mag_thresh[0]) & (sobel_abs <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Threshold color channel\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "\n",
    "    combined_binary[(s_binary == 1) | (sobel_binary == 1)] = 1\n",
    "    combined_binary = np.uint8(255 * combined_binary / np.max(combined_binary))\n",
    "    #show_image(combined_binary)\n",
    "\n",
    "    Perspective_img1=(warp(combined_binary,src,dst))\n",
    "\n",
    "    Perspective_img=(warp(threshInv,src,dst))\n",
    "\n",
    "    image_with_sliding_window, left_fit, right_fit = sliding_window(Perspective_img1)\n",
    "\n",
    "    final_image = draw_lines_and_fill(frm_list[i], Perspective_img1, left_fit, right_fit, src, dst)\n",
    "    final_list.append(final_image)\n",
    "    \n",
    "    \n",
    "    ploty = np.linspace(0, frm_list[i].shape[0] - 1, frm_list[i].shape[0])\n",
    "    # Left line polynomial.\n",
    "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    # Right Line polynomial.\n",
    "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "\n",
    "        \n",
    "    left_curverad, right_curverad =  measure_curvature_meters(Perspective_img1, left_fitx, right_fitx, ploty)\n",
    "    #print('left curve radius in meters  = ', left_curverad)\n",
    "    #print('right curve radius in meters = ', right_curverad)\n",
    "    veh_pos = measure_position_meters(Perspective_img1, left_fit, right_fit)\n",
    "    #print('vehicle position relative to center  = ', veh_pos)\n",
    "    \n",
    "    \n",
    "    cv2.putText(final_image,'Curve Radius [m]: '+str((left_curverad+right_curverad)/2)[:7],(40,70), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.6, (255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(final_image,'Center Offset [m]: '+str(veh_pos)[:7],(40,150), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.6,(255,255,255),2,cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Generating Output Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count = 0\n",
    "#for image in final_list:\n",
    "#    cv2.imwrite(r'.\\Project_data\\frames\\frame%d.jpg' % count, image) #saving frames as jpg\n",
    "#    count += 1\n",
    "    \n",
    "out = cv2.VideoWriter('project_video_result.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 25, size)\n",
    " \n",
    "for i in range(len(final_list)):\n",
    "    out.write(final_list[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#A different way for processing the video frames & Generating a new output video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frames(image):\n",
    "    height, width, layers = image.shape\n",
    "    size = (width,height)\n",
    "    \n",
    "    src = [595, 452], \\\n",
    "          [685, 452], \\\n",
    "          [1110, image.shape[0]], \\\n",
    "          [220, image.shape[0]]\n",
    "    line_dst_offset = 100\n",
    "    dst = [src[3][0] + line_dst_offset, 0], \\\n",
    "          [src[2][0] - line_dst_offset, 0], \\\n",
    "          [src[2][0] - line_dst_offset, src[2][1]], \\\n",
    "          [src[3][0] + line_dst_offset, src[3][1]]\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #cannyed_image = cv2.Canny(gray,100,200, L2gradient = True)\n",
    "    blurred = gaussian_blur(gray,7,7)\n",
    "    cropped_image = region_of_interest(\n",
    "        blurred,\n",
    "        np.array([region_of_interest_vertices], np.int32)\n",
    "    )\n",
    "\n",
    "    (T, threshInv) = cv2.threshold(cropped_image, 200, 255,cv2.THRESH_BINARY)\n",
    "    #cv2.imshow(\"Threshold Binary Inverse\", threshInv)\n",
    "    #show_image(threshInv)\n",
    "    masked = cv2.bitwise_and(image, image, mask=threshInv)\n",
    "    #plt.imshow(masked)\n",
    "    #show_image(masked)\n",
    "\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    gray = hls[:, :, 1]\n",
    "    s_channel = hls[:, :, 2]\n",
    "\n",
    "    sobel_kernel=7\n",
    "    mag_thresh=(3, 255)\n",
    "    s_thresh=(170, 255)\n",
    "    th=(10,100)\n",
    "\n",
    "    sobel_binary = np.zeros(shape=gray.shape, dtype=bool)\n",
    "    s_binary = sobel_binary\n",
    "    combined_binary = s_binary.astype(np.float32)\n",
    "\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=7)\n",
    "    sobely = 0\n",
    "    #sobelxy = cv2.Sobel(gray, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=7)\n",
    "    #show_image(sobelx)\n",
    "    edges = cv2.Canny(gray, threshold1=100, threshold2=200) # Canny Edge Detection\n",
    "    # Display Canny Edge Detection Image\n",
    "    #show_image(edges)\n",
    "\n",
    "    sobel_abs = np.abs(sobelx**2 + sobely**2)\n",
    "    sobel_abs = np.uint8(255 * sobel_abs / np.max(sobel_abs))\n",
    "\n",
    "    sobel_binary[(sobel_abs > mag_thresh[0]) & (sobel_abs <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Threshold color channel\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "\n",
    "    combined_binary[(s_binary == 1) | (sobel_binary == 1)] = 1\n",
    "    combined_binary = np.uint8(255 * combined_binary / np.max(combined_binary))\n",
    "    #show_image(combined_binary)\n",
    "\n",
    "    Perspective_img1=(warp(combined_binary,src,dst))\n",
    "\n",
    "    Perspective_img=(warp(threshInv,src,dst))\n",
    "\n",
    "    image_with_sliding_window, left_fit, right_fit = sliding_window(Perspective_img1)\n",
    "\n",
    "    final_image = draw_lines_and_fill(image, Perspective_img1, left_fit, right_fit, src, dst)\n",
    "    #final_list.append(final_image)\n",
    "    \n",
    "    \n",
    "    ploty = np.linspace(0, image.shape[0] - 1, image.shape[0])\n",
    "    # Left line polynomial.\n",
    "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    # Right Line polynomial.\n",
    "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "\n",
    "        \n",
    "    left_curverad, right_curverad =  measure_curvature_meters(Perspective_img1, left_fitx, right_fitx, ploty)\n",
    "    #print('left curve radius in meters  = ', left_curverad)\n",
    "    #print('right curve radius in meters = ', right_curverad)\n",
    "    veh_pos = measure_position_meters(Perspective_img1, left_fit, right_fit)\n",
    "    #print('vehicle position relative to center  = ', veh_pos)\n",
    "    \n",
    "    \n",
    "    cv2.putText(final_image,'Curve Radius [m]: '+str((left_curverad+right_curverad)/2)[:7],(40,70), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.6, (255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(final_image,'Center Offset [m]: '+str(veh_pos)[:7],(40,150), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.6,(255,255,255),2,cv2.LINE_AA)\n",
    "    \n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|▎                                                                    | 2/485 [00:00<00:31, 15.22it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video trial.mp4.\n",
      "Moviepy - Writing video trial.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready trial.mp4\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "video_output = 'trial.mp4'\n",
    "clip1 = VideoFileClip(r'.\\Project_data\\challenge_video.mp4')\n",
    "output_clip = clip1.fl_image(process_frames)\n",
    "%time output_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('./Project_data/project_video.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, i = cap.read()\n",
    "\n",
    "    if i is None:\n",
    "        break\n",
    "    cv2.imshow('frame', process_frames(i))\n",
    "\n",
    "    # img_array.append(img)\n",
    "\n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
